/* Copyright 2022 The ModelarDB Contributors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

//! The types used throughout the system.
//!
//! Use declarations are purposely not used to minimize the chance of accidentally defining
//! incorrect aliases if types from different modules use the same name. It is assumed that each set
//! of aliases are all for the same underlying type.

use std::fmt;
use std::result::Result as StdResult;
use std::str::FromStr;
use std::sync::Arc;

use arrow::array::{RecordBatch, StringArray};
use arrow::datatypes::{ArrowPrimitiveType, DataType, Schema};
use datafusion::common::{DFSchema, DataFusionError};
use datafusion::logical_expr::Expr;

use crate::error::{ModelarDbTypesError, Result};
use crate::schemas::COMPRESSED_SCHEMA;

// Types used for a single timestamp.
pub type Timestamp = std::primitive::i64; // It is signed to match TimestampMicrosecondType.
pub type ArrowTimestamp = arrow::datatypes::TimestampMicrosecondType;

// Types used for a collection of timestamps.
pub type TimestampBuilder = arrow::array::PrimitiveBuilder<ArrowTimestamp>;
pub type TimestampArray = arrow::array::PrimitiveArray<ArrowTimestamp>;

// Types used for a single value.
pub type Value = std::primitive::f32;
pub type ArrowValue = arrow::datatypes::Float32Type;

// Types used for a collection of values.
pub type ValueBuilder = arrow::array::PrimitiveBuilder<ArrowValue>;
pub type ValueArray = arrow::array::PrimitiveArray<ArrowValue>;

// Types used for the schema of compressed data, the configuration, and table metadata.
#[derive(Clone)]
pub struct CompressedSchema(pub Arc<Schema>);

#[derive(Clone)]
pub struct QueryCompressedSchema(pub Arc<Schema>);

#[derive(Clone)]
pub struct GridSchema(pub Arc<Schema>);

/// Metadata required to ingest data into a time series table and query a time series table.
#[derive(Debug, Clone)]
pub struct TimeSeriesTableMetadata {
    /// Name of the time series table.
    pub name: String,
    /// Index of the timestamp column in `schema`.
    pub timestamp_column_index: usize,
    /// Indices of the field columns in `schema`.
    pub field_column_indices: Vec<usize>,
    /// Indices of the tag columns in `schema`.
    pub tag_column_indices: Vec<usize>,
    /// Error bounds of the columns in `schema`. It can only be non-zero for field columns.
    pub error_bounds: Vec<ErrorBound>,
    /// Expressions to create generated columns in the `query_schema`. Only field columns can be
    /// generated by [`Expr`], so [`None`] is stored for timestamp, tag, and stored field columns.
    pub generated_columns: Vec<Option<GeneratedColumn>>,
    /// Schema of the data that can be written to the time series table.
    pub schema: Arc<Schema>,
    /// Schema of the data that can be read from the time series table.
    pub query_schema: Arc<Schema>,
    /// Projection that changes `query_schema` to `schema`.
    pub query_schema_to_schema: Vec<usize>,
    /// Schema of the compressed segments that are stored in the time series table.
    pub compressed_schema: Arc<Schema>,
}

impl TimeSeriesTableMetadata {
    /// Create a new time series table with the given metadata. If any of the following conditions
    /// are true, [`ModelarDbTypesError`] is returned:
    /// * The number of error bounds does not match the number of columns.
    /// * The number of potentially generated columns does not match the number of columns.
    /// * A generated column includes another generated column in its expression.
    /// * There are more than 32767 columns.
    /// * The `query_schema` does not include a single timestamp column.
    /// * The `query_schema` does not include at least one stored field column.
    pub fn try_new(
        name: String,
        query_schema: Arc<Schema>,
        error_bounds: Vec<ErrorBound>,
        generated_columns: Vec<Option<GeneratedColumn>>,
    ) -> Result<Self> {
        // If an error bound is not defined for each column, return an error.
        if query_schema.fields().len() != error_bounds.len() {
            return Err(ModelarDbTypesError::InvalidArgument(
                "An error bound must be defined for each column.".to_owned(),
            ));
        }

        // If a generated column or None is not defined for each column, return an error.
        if query_schema.fields().len() != generated_columns.len() {
            return Err(ModelarDbTypesError::InvalidArgument(
                "A generated column or None must be defined for each column.".to_owned(),
            ));
        }

        // If a generated field column depends on other generated field columns, return an error.
        for generated_column in generated_columns.iter().flatten() {
            for source_column in &generated_column.source_columns {
                if generated_columns[*source_column].is_some() {
                    return Err(ModelarDbTypesError::InvalidArgument(
                        "A generated field column cannot depend on generated field columns."
                            .to_owned(),
                    ));
                }
            }
        }

        // If there are more than 32767 columns, return an error. This limitation is necessary since
        // 16 bits are used for the field column index in the compressed segments.
        if query_schema.fields.len() > 32767 {
            return Err(ModelarDbTypesError::InvalidArgument(
                "There cannot be more than 32767 columns in the time series table.".to_owned(),
            ));
        }

        // Remove the generated field columns from the query schema and the error bounds as these
        // columns should never be provided when inserting data points into the time series table.
        let mut fields_without_generated = Vec::with_capacity(query_schema.fields().len());
        let mut field_indices_without_generated = Vec::with_capacity(query_schema.fields().len());
        let mut error_bounds_without_generated = Vec::with_capacity(error_bounds.len());
        for (index, generated_column) in generated_columns.iter().enumerate() {
            if generated_column.is_none() {
                fields_without_generated.push(query_schema.fields[index].clone());
                field_indices_without_generated.push(index);
                error_bounds_without_generated.push(error_bounds[index]);
            }
        }

        let schema_without_generated =
            if query_schema.fields.len() != fields_without_generated.len() {
                Arc::new(Schema::new(fields_without_generated))
            } else {
                query_schema.clone()
            };

        // A time series table must only contain one stored timestamp column, one or more stored
        // field columns, zero or more generated field columns, and zero or more stored tag columns.
        let timestamp_column_indices = compute_indices_of_columns_with_data_type(
            &schema_without_generated,
            ArrowTimestamp::DATA_TYPE,
        );

        if timestamp_column_indices.len() != 1 {
            return Err(ModelarDbTypesError::InvalidArgument(
                "There needs to be exactly one timestamp column.".to_owned(),
            ));
        }

        let field_column_indices = compute_indices_of_columns_with_data_type(
            &schema_without_generated,
            ArrowValue::DATA_TYPE,
        );

        if field_column_indices.is_empty() {
            return Err(ModelarDbTypesError::InvalidArgument(
                "There needs to be at least one field column.".to_owned(),
            ));
        }

        let tag_column_indices =
            compute_indices_of_columns_with_data_type(&schema_without_generated, DataType::Utf8);

        // Add the tag columns to the base schema for compressed segments.
        let mut compressed_schema_fields =
            Vec::with_capacity(COMPRESSED_SCHEMA.0.fields().len() + tag_column_indices.len());
        compressed_schema_fields.extend(COMPRESSED_SCHEMA.0.fields.clone().to_vec());

        for index in &tag_column_indices {
            compressed_schema_fields.push(Arc::new(schema_without_generated.field(*index).clone()));
        }

        let compressed_schema = Arc::new(Schema::new(compressed_schema_fields));

        Ok(Self {
            name,
            timestamp_column_index: timestamp_column_indices[0],
            field_column_indices,
            tag_column_indices,
            error_bounds: error_bounds_without_generated,
            generated_columns,
            schema: schema_without_generated,
            query_schema,
            query_schema_to_schema: field_indices_without_generated,
            compressed_schema,
        })
    }

    /// Return `true` if the column at `index` is the timestamp column.
    pub fn is_timestamp(&self, index: usize) -> bool {
        index == self.timestamp_column_index
    }

    /// Return `true` if the column at `index` is a tag column.
    pub fn is_tag(&self, index: usize) -> bool {
        self.tag_column_indices.contains(&index)
    }

    /// Return the column arrays for the timestamp, field, and tag columns in `record_batch`. If
    /// `record_batch` does not contain the required columns, return [`ModelarDbTypesError`].
    pub fn column_arrays<'a>(
        &self,
        record_batch: &'a RecordBatch,
    ) -> Result<(
        &'a TimestampArray,
        Vec<&'a ValueArray>,
        Vec<&'a StringArray>,
    )> {
        if record_batch.schema() != self.schema {
            return Err(ModelarDbTypesError::InvalidArgument(
                "The record batch does not match the schema of the time series table.".to_owned(),
            ));
        }

        let timestamp_column_array =
            crate::array!(record_batch, self.timestamp_column_index, TimestampArray);

        let field_column_arrays: Vec<_> = self
            .field_column_indices
            .iter()
            .map(|index| crate::array!(record_batch, *index, ValueArray))
            .collect();

        let tag_column_arrays: Vec<_> = self
            .tag_column_indices
            .iter()
            .map(|index| crate::array!(record_batch, *index, StringArray))
            .collect();

        Ok((
            timestamp_column_array,
            field_column_arrays,
            tag_column_arrays,
        ))
    }
}

/// Compute the indices of all columns in `schema` with `data_type`.
fn compute_indices_of_columns_with_data_type(schema: &Schema, data_type: DataType) -> Vec<usize> {
    let fields = schema.fields();
    (0..fields.len())
        .filter(|index| *fields[*index].data_type() == data_type)
        .collect()
}

/// Absolute or relative per-value error bound.
#[derive(Debug, Copy, Clone, PartialEq)]
pub enum ErrorBound {
    /// An error bound that guarantees each value cannot deviate more than the [`Value`].
    Absolute(Value),
    /// An error bound that guarantees each value cannot deviate more than 0.0% to 100.0%.
    Relative(f32),
}

impl ErrorBound {
    /// Return an [`ErrorBound::Absolute`] with `value` as its absolute per-value bound. A
    /// [`ModelarDbTypesError`] is returned if a negative or non-normal value is passed.
    pub fn try_new_absolute(value: f32) -> Result<Self> {
        if !value.is_finite() || value < 0.0 {
            Err(ModelarDbTypesError::InvalidArgument(
                "An absolute error bound must be a positive finite value.".to_owned(),
            ))
        } else {
            Ok(Self::Absolute(value))
        }
    }

    /// Return an [`ErrorBound::Relative`] with `percentage` as its relative per-value bound. A
    /// [`ModelarDbTypesError`] is returned if a value below 0% or a value above 100% is passed.
    pub fn try_new_relative(percentage: f32) -> Result<Self> {
        if !(0.0..=100.0).contains(&percentage) {
            Err(ModelarDbTypesError::InvalidArgument(
                "A relative error bound must be a value from 0.0% to 100.0%.".to_owned(),
            ))
        } else {
            Ok(Self::Relative(percentage))
        }
    }
}

/// Column that is generated by an [`Expr`] using zero or more stored columns as input.
#[derive(Clone, Debug, PartialEq)]
pub struct GeneratedColumn {
    /// Logical expression that computes the values of the column.
    pub expr: Expr,
    /// Indices of the stored columns used by `expr` to compute the column's values.
    pub source_columns: Vec<usize>,
}

impl GeneratedColumn {
    /// Return a new [`GeneratedColumn`] with the given expression if it only references columns in
    /// [`DFSchema`], otherwise return [`ModelarDbTypesError`].
    pub fn try_from_expr(expr: Expr, df_schema: &DFSchema) -> Result<Self> {
        let source_columns: StdResult<Vec<usize>, DataFusionError> = expr
            .column_refs()
            .iter()
            .map(|column| df_schema.index_of_column(column))
            .collect();

        Ok(Self {
            expr,
            source_columns: source_columns?,
        })
    }
}

/// A single ModelarDB server that is controlled by the manager. The node can either be an edge node
/// or a cloud node. A node cannot be another manager.
#[derive(Debug, Clone, PartialEq)]
pub struct Node {
    /// Apache Arrow Flight URL for the node. This URL uniquely identifies the node.
    pub url: String,
    /// The mode the node was started in.
    pub mode: ServerMode,
}

impl Node {
    pub fn new(url: String, mode: ServerMode) -> Self {
        Self { url, mode }
    }
}

/// The different possible modes of a ModelarDB server, assigned when the server is started.
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ServerMode {
    Cloud,
    Edge,
}

impl FromStr for ServerMode {
    type Err = ModelarDbTypesError;

    fn from_str(value: &str) -> Result<Self> {
        match value {
            "cloud" => Ok(ServerMode::Cloud),
            "edge" => Ok(ServerMode::Edge),
            _ => Err(ModelarDbTypesError::InvalidArgument(format!(
                "'{value}' is not a valid value for ServerMode."
            ))),
        }
    }
}

impl fmt::Display for ServerMode {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            ServerMode::Cloud => write!(f, "cloud"),
            ServerMode::Edge => write!(f, "edge"),
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    use arrow::datatypes::Field;
    use proptest::num;
    use proptest::proptest;

    use modelardb_common::test::ERROR_BOUND_ZERO;
    use modelardb_storage::test;

    // Tests for TimeSeriesTableMetadata.
    #[test]
    fn test_can_create_time_series_table_metadata() {
        let (query_schema, error_bounds, generated_columns) =
            time_series_table_schema_error_bounds_and_generated_columns();
        let result = TimeSeriesTableMetadata::try_new(
            test::TIME_SERIES_TABLE_NAME.to_owned(),
            query_schema,
            error_bounds,
            generated_columns,
        );

        assert!(result.is_ok());
    }

    #[test]
    fn test_cannot_create_time_series_table_metadata_with_invalid_timestamp_type() {
        let schema = Schema::new(vec![
            Field::new("tag", DataType::Utf8, false),
            Field::new("timestamp", DataType::UInt8, false),
            Field::new("value", ArrowValue::DATA_TYPE, false),
        ]);

        let result = create_simple_time_series_table_metadata(schema);
        assert!(result.is_err());
    }

    #[test]
    fn test_cannot_create_time_series_table_metadata_with_invalid_tag_type() {
        let schema = Schema::new(vec![
            Field::new("tag", DataType::UInt8, false),
            Field::new("timestamp", ArrowTimestamp::DATA_TYPE, false),
            Field::new("value", ArrowValue::DATA_TYPE, false),
        ]);

        let result = create_simple_time_series_table_metadata(schema);
        assert!(result.is_err());
    }

    #[test]
    fn test_cannot_create_time_series_table_metadata_with_no_fields() {
        let schema = Schema::new(vec![
            Field::new("tag", DataType::Utf8, false),
            Field::new("timestamp", ArrowTimestamp::DATA_TYPE, false),
        ]);

        let result = create_simple_time_series_table_metadata(schema);
        assert!(result.is_err());
    }

    #[test]
    fn test_cannot_create_time_series_table_metadata_with_invalid_field_type() {
        let schema = Schema::new(vec![
            Field::new("tag", DataType::Utf8, false),
            Field::new("timestamp", ArrowTimestamp::DATA_TYPE, false),
            Field::new("value", DataType::UInt8, false),
        ]);

        let result = create_simple_time_series_table_metadata(schema);
        assert!(result.is_err());
    }

    /// Return metadata for a time series table with one tag column and the timestamp column at index 1.
    fn create_simple_time_series_table_metadata(
        query_schema: Schema,
    ) -> Result<TimeSeriesTableMetadata> {
        TimeSeriesTableMetadata::try_new(
            test::TIME_SERIES_TABLE_NAME.to_owned(),
            Arc::new(query_schema),
            vec![ErrorBound::try_new_absolute(ERROR_BOUND_ZERO).unwrap()],
            vec![None],
        )
    }

    #[test]
    fn test_cannot_create_time_series_table_metadata_with_missing_or_too_many_error_bounds() {
        let (query_schema, _error_bounds, generated_columns) =
            time_series_table_schema_error_bounds_and_generated_columns();
        let result = TimeSeriesTableMetadata::try_new(
            test::TIME_SERIES_TABLE_NAME.to_owned(),
            query_schema,
            vec![],
            generated_columns,
        );

        assert!(result.is_err());
    }

    #[test]
    fn test_cannot_create_time_series_table_metadata_with_missing_or_too_many_generated_columns() {
        let (query_schema, error_bounds, _generated_columns) =
            time_series_table_schema_error_bounds_and_generated_columns();
        let result = TimeSeriesTableMetadata::try_new(
            test::TIME_SERIES_TABLE_NAME.to_owned(),
            query_schema,
            error_bounds,
            vec![],
        );

        assert!(result.is_err());
    }

    #[test]
    fn test_cannot_create_time_series_table_metadata_with_generated_columns_using_generated_columns()
     {
        let (query_schema, error_bounds, mut generated_columns) =
            time_series_table_schema_error_bounds_and_generated_columns();

        generated_columns[5] = Some(GeneratedColumn {
            expr: Expr::Column("".into()),
            source_columns: vec![],
        });

        generated_columns[6] = Some(GeneratedColumn {
            expr: Expr::Column("".into()),
            source_columns: vec![5],
        });

        let result = TimeSeriesTableMetadata::try_new(
            test::TIME_SERIES_TABLE_NAME.to_owned(),
            query_schema,
            error_bounds,
            generated_columns,
        );

        assert!(result.is_err());
    }

    fn time_series_table_schema_error_bounds_and_generated_columns()
    -> (Arc<Schema>, Vec<ErrorBound>, Vec<Option<GeneratedColumn>>) {
        (
            Arc::new(Schema::new(vec![
                Field::new("location", DataType::Utf8, false),
                Field::new("install_year", DataType::Utf8, false),
                Field::new("model", DataType::Utf8, false),
                Field::new("timestamp", ArrowTimestamp::DATA_TYPE, false),
                Field::new("power_output", ArrowValue::DATA_TYPE, false),
                Field::new("wind_speed", ArrowValue::DATA_TYPE, false),
                Field::new("temperature", ArrowValue::DATA_TYPE, false),
            ])),
            vec![
                ErrorBound::try_new_absolute(ERROR_BOUND_ZERO).unwrap(),
                ErrorBound::try_new_absolute(ERROR_BOUND_ZERO).unwrap(),
                ErrorBound::try_new_relative(ERROR_BOUND_ZERO).unwrap(),
                ErrorBound::try_new_absolute(ERROR_BOUND_ZERO).unwrap(),
                ErrorBound::try_new_absolute(ERROR_BOUND_ZERO).unwrap(),
                ErrorBound::try_new_relative(ERROR_BOUND_ZERO).unwrap(),
                ErrorBound::try_new_relative(ERROR_BOUND_ZERO).unwrap(),
            ],
            vec![None, None, None, None, None, None, None],
        )
    }

    #[test]
    fn test_is_timestamp() {
        let time_series_table_metadata = test::time_series_table_metadata();

        assert!(time_series_table_metadata.is_timestamp(0));
        assert!(!time_series_table_metadata.is_timestamp(1));
        assert!(!time_series_table_metadata.is_timestamp(2));
        assert!(!time_series_table_metadata.is_timestamp(3));
    }

    #[test]
    fn test_is_tag() {
        let time_series_table_metadata = test::time_series_table_metadata();

        assert!(!time_series_table_metadata.is_tag(0));
        assert!(!time_series_table_metadata.is_tag(1));
        assert!(!time_series_table_metadata.is_tag(2));
        assert!(time_series_table_metadata.is_tag(3));
    }

    #[test]
    fn test_column_arrays() {
        let time_series_table_metadata = test::time_series_table_metadata();
        let record_batch = test::uncompressed_time_series_table_record_batch(1);

        let (timestamp_column_array, field_column_arrays, tag_column_arrays) =
            time_series_table_metadata
                .column_arrays(&record_batch)
                .unwrap();

        assert_eq!(
            crate::array!(record_batch, 0, TimestampArray),
            timestamp_column_array
        );
        assert_eq!(
            crate::array!(record_batch, 1, ValueArray),
            field_column_arrays[0]
        );
        assert_eq!(
            crate::array!(record_batch, 2, ValueArray),
            field_column_arrays[1]
        );
        assert_eq!(
            crate::array!(record_batch, 3, StringArray),
            tag_column_arrays[0]
        );
    }

    #[test]
    fn test_column_arrays_with_invalid_schema() {
        let time_series_table_metadata = test::time_series_table_metadata();
        let record_batch = test::normal_table_record_batch();

        let result = time_series_table_metadata.column_arrays(&record_batch);

        assert_eq!(
            result.unwrap_err().to_string(),
            "Invalid Argument Error: The record batch does not match the schema of the time series table."
        );
    }

    // Tests for ErrorBound.
    #[test]
    fn test_absolute_error_bound_can_be_zero() {
        assert!(ErrorBound::try_new_absolute(ERROR_BOUND_ZERO).is_ok())
    }

    proptest! {
        #[test]
        fn test_absolute_error_bound_can_be_any_positive_value(value in num::f32::POSITIVE) {
            assert!(ErrorBound::try_new_absolute(value).is_ok())
        }

        #[test]
        fn test_absolute_error_bound_cannot_be_negative(value in num::f32::NEGATIVE) {
            assert!(ErrorBound::try_new_absolute(value).is_err())
        }
    }

    #[test]
    fn test_absolute_error_bound_cannot_be_positive_infinity() {
        assert!(ErrorBound::try_new_absolute(f32::INFINITY).is_err())
    }

    #[test]
    fn test_absolute_error_bound_cannot_be_negative_infinity() {
        assert!(ErrorBound::try_new_absolute(f32::NEG_INFINITY).is_err())
    }

    #[test]
    fn test_absolute_error_bound_cannot_be_nan() {
        assert!(ErrorBound::try_new_absolute(f32::NAN).is_err())
    }

    #[test]
    fn test_relative_error_bound_can_be_zero() {
        assert!(ErrorBound::try_new_relative(ERROR_BOUND_ZERO).is_ok())
    }

    proptest! {
        #[test]
        fn test_relative_error_bound_can_be_positive_if_less_than_one_hundred(percentage in num::f32::POSITIVE) {
            if percentage <= 100.0 {
                assert!(ErrorBound::try_new_relative(percentage).is_ok())
            } else {
                assert!(ErrorBound::try_new_relative(percentage).is_err())
            }
        }

        #[test]
        fn test_relative_error_bound_cannot_be_negative(percentage in num::f32::NEGATIVE) {
            assert!(ErrorBound::try_new_relative(percentage).is_err())
        }
    }

    #[test]
    fn test_relative_error_bound_cannot_be_positive_infinity() {
        assert!(ErrorBound::try_new_relative(f32::INFINITY).is_err())
    }

    #[test]
    fn test_relative_error_bound_cannot_be_negative_infinity() {
        assert!(ErrorBound::try_new_relative(f32::NEG_INFINITY).is_err())
    }

    #[test]
    fn test_relative_error_bound_cannot_be_nan() {
        assert!(ErrorBound::try_new_relative(f32::NAN).is_err())
    }
}
